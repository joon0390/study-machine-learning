{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKj6GbvQpYiVE6vOZrWWJL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimgoinghard/study-machine-learning/blob/main/study_torch_12_xor_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#퍼셉트론(Perceptron)\n",
        "- 퍼셉트론은 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내는 알고리즘."
      ],
      "metadata": {
        "id": "P6sfiX1ZOoVL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RNQnOhz-Gpcd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #gpu연산이 가능한 경우엔 gpu연산을 할 수 있도록 설정해준다. \n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "OETzT7xEM8OF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0,0], [0,1], [1,0], [1,1] ]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "hzOeSFrZNR5X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(2, 1, bias=True) #linear 층 \n",
        "sigmoid = nn.Sigmoid() #시그모이드 층 \n",
        "model = nn.Sequential(linear, sigmoid).to(device) #nn.Sequential()로 linear, sigmoid 를 쌓은 계층 만들고 model 객체에 저장하고 gpu에서 시작."
      ],
      "metadata": {
        "id": "TwmUr1okOjwX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)"
      ],
      "metadata": {
        "id": "HWwVip_0QTNG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(10001):\n",
        "  optimizer.zero_grad()\n",
        "  hypo = model(X)\n",
        "\n",
        "  cost = criterion(hypo, Y)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if step % 100 == 0:\n",
        "    print(step, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzllz8-sTf3P",
        "outputId": "fa012a1b-3b07-4efb-c4f2-bb9c1eac1916"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6931471824645996\n",
            "100 0.6931471824645996\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  hypo = model(X)\n",
        "  predicted = (hypo > 0.5).float()\n",
        "  accuracy = (predicted == Y).float().mean()\n",
        "  print('모델의 출력값 : \\n ', hypo.detach().cpu().numpy())\n",
        "  print('모델의 예측값 : \\n', predicted.detach().cpu().numpy())\n",
        "  print('실제값(Y) : \\n', Y.cpu().numpy())\n",
        "  print('정확도(Accuracy) : ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_fJYY5DUOis",
        "outputId": "11c7d6bf-c7c9-4b97-b936-c4ec3458dfe5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 출력값 : \n",
            "  [[1.1168801e-04]\n",
            " [9.9982882e-01]\n",
            " [9.9984229e-01]\n",
            " [1.8529482e-04]]\n",
            "모델의 예측값 : \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "실제값(Y) : \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy) :  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단층 퍼셉트론은 XOR문제를 풀지 못하는 모습을 볼 수있다. "
      ],
      "metadata": {
        "id": "tCsrYb1xV_Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Ec04gBhxV3QE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #gpu사용 설정\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "4suRk60-WQr5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device) #gpu에서 계산한다.\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "B99c1dRkWjId"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2,10, bias = True), #input_layer = 2, hidden_layer = 10\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,10, bias = True), # 10 x 10\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,10, bias = True), # 10 x 10\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(10,1, bias = True), # 10 x 1\n",
        "    nn.Sigmoid()\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "vZoWTxF7Wo0z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss().to(device) #이진분류에서 사용하는 크로스엔트로피 함수이다.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)  #학습률 : 1"
      ],
      "metadata": {
        "id": "xkJ2m2BrXVyS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10001):\n",
        "  optimizer.zero_grad()\n",
        "  #forward\n",
        "  hypo = model(X)\n",
        "\n",
        "  cost = criterion(hypo, Y)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(epoch, cost.item())\n",
        "\n",
        "\n",
        "#모델 학습시키기."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNGL4cOgXngC",
        "outputId": "0c9136ab-a79a-41b1-b595-fccbf6b10007"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6948983669281006\n",
            "100 0.693155825138092\n",
            "200 0.6931535601615906\n",
            "300 0.6931513547897339\n",
            "400 0.6931493282318115\n",
            "500 0.6931473016738892\n",
            "600 0.6931453943252563\n",
            "700 0.6931434869766235\n",
            "800 0.6931416988372803\n",
            "900 0.6931397914886475\n",
            "1000 0.6931379437446594\n",
            "1100 0.6931361556053162\n",
            "1200 0.6931343078613281\n",
            "1300 0.6931324005126953\n",
            "1400 0.6931304931640625\n",
            "1500 0.6931284666061401\n",
            "1600 0.6931264400482178\n",
            "1700 0.6931242942810059\n",
            "1800 0.6931220293045044\n",
            "1900 0.6931197047233582\n",
            "2000 0.6931172013282776\n",
            "2100 0.6931145191192627\n",
            "2200 0.6931115984916687\n",
            "2300 0.6931084990501404\n",
            "2400 0.6931051015853882\n",
            "2500 0.6931014657020569\n",
            "2600 0.6930974721908569\n",
            "2700 0.6930930018424988\n",
            "2800 0.6930879950523376\n",
            "2900 0.6930825114250183\n",
            "3000 0.6930762529373169\n",
            "3100 0.6930692195892334\n",
            "3200 0.6930611729621887\n",
            "3300 0.6930519342422485\n",
            "3400 0.6930411458015442\n",
            "3500 0.6930283904075623\n",
            "3600 0.6930132508277893\n",
            "3700 0.6929951310157776\n",
            "3800 0.6929728984832764\n",
            "3900 0.6929452419281006\n",
            "4000 0.6929103136062622\n",
            "4100 0.6928649544715881\n",
            "4200 0.6928046941757202\n",
            "4300 0.692721962928772\n",
            "4400 0.6926040649414062\n",
            "4500 0.6924278140068054\n",
            "4600 0.6921480298042297\n",
            "4700 0.6916665434837341\n",
            "4800 0.690739631652832\n",
            "4900 0.6886204481124878\n",
            "5000 0.6820822358131409\n",
            "5100 0.6472561359405518\n",
            "5200 0.4511455297470093\n",
            "5300 0.0417914092540741\n",
            "5400 0.00976566132158041\n",
            "5500 0.005042724311351776\n",
            "5600 0.003299684962257743\n",
            "5700 0.0024178465828299522\n",
            "5800 0.0018926756456494331\n",
            "5900 0.0015468898927792907\n",
            "6000 0.0013032691786065698\n",
            "6100 0.0011230817763134837\n",
            "6200 0.0009846779284998775\n",
            "6300 0.0008753472939133644\n",
            "6400 0.0007869074470363557\n",
            "6500 0.0007139394292607903\n",
            "6600 0.0006528611993417144\n",
            "6700 0.0006009416538290679\n",
            "6800 0.0005563456215895712\n",
            "6900 0.0005176705890335143\n",
            "7000 0.0004838125314563513\n",
            "7100 0.00045392123865894973\n",
            "7200 0.0004273701924830675\n",
            "7300 0.0004036074969917536\n",
            "7400 0.0003822603903245181\n",
            "7500 0.0003629559651017189\n",
            "7600 0.0003454257966950536\n",
            "7700 0.00032946106512099504\n",
            "7800 0.0003148381656501442\n",
            "7900 0.00030137813882902265\n",
            "8000 0.00028903622296638787\n",
            "8100 0.0002775738830678165\n",
            "8200 0.0002669761888682842\n",
            "8300 0.00025713874492794275\n",
            "8400 0.0002479125396348536\n",
            "8500 0.00023935710487421602\n",
            "8600 0.00023135324590839446\n",
            "8700 0.00022382638417184353\n",
            "8800 0.00021674673189409077\n",
            "8900 0.0002101142454193905\n",
            "9000 0.0002038097009062767\n",
            "9100 0.00019787781639024615\n",
            "9200 0.00019228874589316547\n",
            "9300 0.00018698288477025926\n",
            "9400 0.00018196026212535799\n",
            "9500 0.00017717608716338873\n",
            "9600 0.00017263043264392763\n",
            "9700 0.0001683083246462047\n",
            "9800 0.00016420979227405041\n",
            "9900 0.00016027523088268936\n",
            "10000 0.00015648972475901246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  hypo = model(X)\n",
        "  predicted = (hypo > 0.5).float()\n",
        "  accuracy = (predicted == Y).float().mean()\n",
        "  print('모델의 출력값(Hypothesis): \\n ', hypo.detach().cpu().numpy())\n",
        "  print('모델의 예측값(Predicted): \\n ', predicted.detach().cpu().numpy())\n",
        "  print('실제값(Y): \\n', Y.cpu().numpy())\n",
        "  print('정확도(Accuracy): ', accuracy.item())\n",
        "\n",
        "#다층 퍼셉트론을 이용한 결과 올바르게 예측하였다.\n",
        "# detach()는 이 연산 기록으로 부터 분리한 tensor을 반환 -> 해당텐서가 더 이상 그래디언트를 계산할 필요가 없으며 역전파를 위한 추가 계산에 참여하지 않게 된다.\n",
        "# GPU 메모리에 올려져 있는 tensor를 cpu 메모리로 복사하는 method\n",
        "#tensor를 numpy로 변환하여 반환. 이때 저장공간을 공유하기 때문에 하나를 변경하면 다른 하나도 변경된다.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js1nPb0TYFF2",
        "outputId": "be251c09-6954-40e8-e8bd-00991a3d1028"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델의 출력값(Hypothesis): \n",
            "  [[1.1168801e-04]\n",
            " [9.9982882e-01]\n",
            " [9.9984229e-01]\n",
            " [1.8529482e-04]]\n",
            "모델의 예측값(Predicted): \n",
            "  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "실제값(Y): \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "정확도(Accuracy):  1.0\n"
          ]
        }
      ]
    }
  ]
}