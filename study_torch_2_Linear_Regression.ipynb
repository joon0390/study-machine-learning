{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5o0feq/KB/jETrMH7uSpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimgoinghard/study-machine-learning/blob/main/study_torch_2_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "oWh2OCtNLTBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cost Function(비용함수) \n",
        "- 손실함수\n",
        "- 오차함수\n",
        "- 목적함수"
      ],
      "metadata": {
        "id": "6YeKEW2rLioS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "비용함수를 최소화 하는 매개변수를 구함으로서 데이터를 가장 잘 나타내는 직선을 구하는 방법이 선형회귀."
      ],
      "metadata": {
        "id": "UpkJPyQeL_1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞에서 이야기한 비용함수를 최적화하는 방법들 중 Optimizer(최적화) 알고리즘을 사용할 것이다.. 가장 기본적인 optimizer 방법인 Gradient Descent(경사하강법)을 공부해보았다."
      ],
      "metadata": {
        "id": "EYZvqVqNMMO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "qeLLsfoWMwy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 그림은 우리가 찾으려는 매개변수 W, 즉 기울기에 따른 비용함수의 그래프이다. (절편은 생략하였다.)\n",
        "\n",
        "방법은 이와 같다. \n",
        "1. 임의의 초기값 W를 설정한다.\n",
        "2. 현재 W에서의 기울기를 구한다. \n",
        "3. 양수라면 W값을 감소시키고, 음수라면 W값을 증가시킨다. \n",
        "4. 1~3의 과정을 기울기가 0과 아주 가까워질 때 까지 반복한다. \n",
        "\n",
        "이 과정에서 고려해야할 것이 하나 더 있는데, 바로 어느 정도의 크기로 W값을 수정해야하는가 이다. 이를 Learing Rate(학습률) 이라고 부르며, 너무 크게 되면 W값이 발산하게 되고, 너무 작으면 학습속도가 느려지게 되어 적절한 값을 찾아주어야 한다. "
      ],
      "metadata": {
        "id": "Te38Z9UaM8JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "OWWLBkwpLhV2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]]) #공부시간\n",
        "y_train = torch.FloatTensor([[2], [4], [6]]) #점수"
      ],
      "metadata": {
        "id": "GPaiLW5ZO4xA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape) #(3,1)\n",
        "print(x_train)\n",
        "\n",
        "print(y_train.shape) #(3,1)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o6XkkdZO60z",
        "outputId": "b268544a-c5b2-43cb-a642-90da9926c2d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1])\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n",
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#매개변수 초기화\n",
        "W = torch.zeros(1, requires_grad=True) #학습을 통해 값이 변경가능하다는 것.\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaEe95siPMuL",
        "outputId": "88810ac3-5b87-46d0-9593-53ad89ca2652"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_hQ4Dc6SP9dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.zeros(1, requires_grad = True)"
      ],
      "metadata": {
        "id": "WrqWfssZPk1W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "현재 직선의 방정식 \n",
        "#y = 0 * x + 0#\n"
      ],
      "metadata": {
        "id": "mvLl8IoxPwG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = x_train * W + b \n",
        "print(hypothesis) #현재 매개변수들에 의한 직선의 방정식, 귀무가설에 해당함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkYb9xNRPuaH",
        "outputId": "083005a8-4b86-4e73-dc1b-a2bb743358f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost = torch.mean((hypothesis - y_train)**2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MsdgGdIQWzH",
        "outputId": "5eca7da3-f0fe-4c00-aa77-4d64be860593"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01 #학습률\n",
        "optimizer = optim.SGD([W,b], lr) #SGD : Stochastic Gradient Descent(확률적 경사 하강법) / optimizer는 SGD객체."
      ],
      "metadata": {
        "id": "-Zs-b-k_QohH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer.zero_grad()  #미분해서 얻은 기울기를 0으로 초기화한다. 그래야 매개변수를 수정한 뒤에 또 새로운 매개변수를 구해나갈 수 있음.\n",
        "#cost.backward() #비용함수를 미분하여 W와 b를 계산한다.(역전파 이용)\n",
        "#optimizer.step() #backward()를 통해 계산한 매개변수를 update하는 과정"
      ],
      "metadata": {
        "id": "rqcUd1AyRVJU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 2000\n",
        "for epoch in range(n_epochs+1):\n",
        "\n",
        "  hypothesis = x_train*W + b\n",
        "\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad() #0으로 초기화\n",
        "  cost.backward() #역전파 신호로 매개변수 계산\n",
        "  optimizer.step() #계산된 매개변수 업데이트\n",
        "      \n",
        "  if epoch%100 ==0:\n",
        "    print('Epoch {0} / W : {1} / b : {2} / Cost : {3}'.format(epoch, W.item(), b.item(), cost.item() ))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuY3s316SWcj",
        "outputId": "2c9c40c6-dea1-4703-fce3-829d6e66042d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 100 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 200 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 300 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 400 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 500 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 600 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 700 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 800 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 900 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1000 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1100 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1200 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1300 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1400 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1500 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1600 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1700 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1800 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 1900 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n",
            "Epoch 2000 / W : 1.9999957084655762 / b : 8.701807018951513e-06 / Cost : 1.2278178473934531e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#optimizer.zero_grad() 의 역할"
      ],
      "metadata": {
        "id": "fbnuFqOgTz6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs):\n",
        "  z = 2 * w\n",
        "  z.backward()\n",
        "  print('수식을 w로 미분한 값 : {0}'.format(w.grad))\n",
        "\n",
        "#계속 2가 누적되는 것을 볼 수 있다. 따라서 optimizer.zero_grad()를 통해서 0으로 초기화 시켜주어야 한다. \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR3rfAERTvbj",
        "outputId": "a211bf58-8d0c-47d5-ce76-5a0f832f0a69"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값 : 2.0\n",
            "수식을 w로 미분한 값 : 4.0\n",
            "수식을 w로 미분한 값 : 6.0\n",
            "수식을 w로 미분한 값 : 8.0\n",
            "수식을 w로 미분한 값 : 10.0\n",
            "수식을 w로 미분한 값 : 12.0\n",
            "수식을 w로 미분한 값 : 14.0\n",
            "수식을 w로 미분한 값 : 16.0\n",
            "수식을 w로 미분한 값 : 18.0\n",
            "수식을 w로 미분한 값 : 20.0\n",
            "수식을 w로 미분한 값 : 22.0\n",
            "수식을 w로 미분한 값 : 24.0\n",
            "수식을 w로 미분한 값 : 26.0\n",
            "수식을 w로 미분한 값 : 28.0\n",
            "수식을 w로 미분한 값 : 30.0\n",
            "수식을 w로 미분한 값 : 32.0\n",
            "수식을 w로 미분한 값 : 34.0\n",
            "수식을 w로 미분한 값 : 36.0\n",
            "수식을 w로 미분한 값 : 38.0\n",
            "수식을 w로 미분한 값 : 40.0\n"
          ]
        }
      ]
    }
  ]
}