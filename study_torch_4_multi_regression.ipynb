{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyML81i56AUNUEZJema+/j9a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimgoinghard/study-machine-learning/blob/main/study_torch_4_multi_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "변수가 1개인 선형 회귀를 단순선형회귀라고 했다. 변수가 2개 이상인 경우는 다중선형회귀라고 한다. "
      ],
      "metadata": {
        "id": "cumxVCGcXwO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#H(x) = w1x1 + w2x2 + w3x3 + b"
      ],
      "metadata": {
        "id": "3xSbqunyYUJB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DWZ5DSGhXhnA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1) #랜덤시드 고정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MswwAk8XYkGL",
        "outputId": "6b6e803a-a9e1-4ca2-9936-c848758f7c5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7528012070>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "bMDRH1lPYohA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#매개변수 생성 및 초기화\n",
        "w1 = torch.zeros(1, requires_grad = True)\n",
        "w2 = torch.zeros(1, requires_grad = True)\n",
        "w3 = torch.zeros(1, requires_grad = True)\n",
        "b = torch.zeros(1, requires_grad = True)"
      ],
      "metadata": {
        "id": "CBC9QLaLYrN-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([w1,w2,w3,b], lr = 1e-5) "
      ],
      "metadata": {
        "id": "bqi3xWVtY0Vh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs + 1):\n",
        "  #hypo라고 썼지만 y_hat과 같은 의미.\n",
        "  hypo = x1_train*w1 + x2_train*w2 + x3_train*w3 + b\n",
        "\n",
        "  cost = torch.mean((hypo - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100 ==0:\n",
        "    print('Epoch : {0}, w1 : {1}, w2 : {2} , w3 : {3}, b : {4}'.format(epoch, w1.item(), w2.item(), w3.item(), b ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MvTzGTQZLRP",
        "outputId": "790d70b3-fe35-4ea4-e301-dd5788ea316f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0, w1 : 0.29401201009750366, w2 : 0.2935999929904938 , w3 : 0.2973800003528595, b : tensor([0.0034], requires_grad=True)\n",
            "Epoch : 100, w1 : 0.6735064387321472, w2 : 0.6609678864479065 , w3 : 0.6762318015098572, b : tensor([0.0079], requires_grad=True)\n",
            "Epoch : 200, w1 : 0.6789457201957703, w2 : 0.6549615859985352 , w3 : 0.6767846345901489, b : tensor([0.0081], requires_grad=True)\n",
            "Epoch : 300, w1 : 0.6842508316040039, w2 : 0.6491218209266663 , w3 : 0.6773056983947754, b : tensor([0.0082], requires_grad=True)\n",
            "Epoch : 400, w1 : 0.6894257068634033, w2 : 0.643443763256073 , w3 : 0.6777958869934082, b : tensor([0.0084], requires_grad=True)\n",
            "Epoch : 500, w1 : 0.6944737434387207, w2 : 0.6379231810569763 , w3 : 0.6782558560371399, b : tensor([0.0085], requires_grad=True)\n",
            "Epoch : 600, w1 : 0.69939786195755, w2 : 0.6325559616088867 , w3 : 0.678686797618866, b : tensor([0.0087], requires_grad=True)\n",
            "Epoch : 700, w1 : 0.7042017579078674, w2 : 0.6273379325866699 , w3 : 0.679089367389679, b : tensor([0.0088], requires_grad=True)\n",
            "Epoch : 800, w1 : 0.7088885307312012, w2 : 0.6222650408744812 , w3 : 0.6794645190238953, b : tensor([0.0089], requires_grad=True)\n",
            "Epoch : 900, w1 : 0.7134615182876587, w2 : 0.617333173751831 , w3 : 0.6798126697540283, b : tensor([0.0091], requires_grad=True)\n",
            "Epoch : 1000, w1 : 0.7179235816001892, w2 : 0.6125389337539673 , w3 : 0.6801347136497498, b : tensor([0.0092], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 경우에서 x가 3개가 아니라 1000개라고 생각해보자. 그 경우엔 x1~x1000, w1~w1000 매개변수만 2000개를 선언하고 곱해지는 항도 개수가 너무 많아져 상당히 비효율적이라고 할 수 있다. "
      ],
      "metadata": {
        "id": "GzPgDQQPbQbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#그래서! 행렬곱셉을 사용한다. "
      ],
      "metadata": {
        "id": "JC4d9ah7bq8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "#x_train을 (5,3)행렬로 생성했다,"
      ],
      "metadata": {
        "id": "RiYK8erpbOhd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.zeros((3,1), requires_grad = True) \n",
        "b = torch.zeros((5,1), requires_grad = True)"
      ],
      "metadata": {
        "id": "Bs7XCCyccBoi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "w행렬의 차원을 보면 (3,1)인데 이것이 포인트다. 행렬 곱셉에선 앞 행렬의 열과 뒷 행렬의 행이 같아야 한다. 현재 x_train은 (5,3)이다. w는 (3,1)로 곱셈이 가능하다!"
      ],
      "metadata": {
        "id": "BcE4NqtacTy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypo = x_train.matmul(w) + b"
      ],
      "metadata": {
        "id": "Jog9o2QWbApl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1e-5) \n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해진다.\n",
        "    hypo = x_train.matmul(W) + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypo - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad() #0으로 초기화\n",
        "    cost.backward() #역전파로 미분계수 계산\n",
        "    optimizer.step() #미분계수 업데이트\n",
        "\n",
        "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, hypo.squeeze().detach(), cost.item() #hypo 는 (3,1)인데 squeeze해주어 (3,)으로 바뀐다. \n",
        "    )) #detach()는 이후의 연산이 추적되는 것을 방지한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSblPfUWc1mK",
        "outputId": "846883c0-b6e6-4cc2-d09a-9dfc33f3eefd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 hypothesis: tensor([154.0543, 185.1140, 175.7470, 198.6150, 141.2166]) Cost: 5.954494\n",
            "Epoch    1/20 hypothesis: tensor([154.0546, 185.1143, 175.7486, 198.6150, 141.2171]) Cost: 5.951927\n",
            "Epoch    2/20 hypothesis: tensor([154.0547, 185.1143, 175.7500, 198.6147, 141.2173]) Cost: 5.949370\n",
            "Epoch    3/20 hypothesis: tensor([154.0546, 185.1142, 175.7512, 198.6143, 141.2175]) Cost: 5.946794\n",
            "Epoch    4/20 hypothesis: tensor([154.0546, 185.1140, 175.7523, 198.6138, 141.2177]) Cost: 5.944210\n",
            "Epoch    5/20 hypothesis: tensor([154.0545, 185.1137, 175.7535, 198.6133, 141.2178]) Cost: 5.941589\n",
            "Epoch    6/20 hypothesis: tensor([154.0543, 185.1135, 175.7545, 198.6127, 141.2178]) Cost: 5.939054\n",
            "Epoch    7/20 hypothesis: tensor([154.0542, 185.1132, 175.7556, 198.6122, 141.2179]) Cost: 5.936491\n",
            "Epoch    8/20 hypothesis: tensor([154.0541, 185.1129, 175.7567, 198.6116, 141.2180]) Cost: 5.933901\n",
            "Epoch    9/20 hypothesis: tensor([154.0539, 185.1126, 175.7578, 198.6110, 141.2180]) Cost: 5.931320\n",
            "Epoch   10/20 hypothesis: tensor([154.0538, 185.1123, 175.7588, 198.6104, 141.2181]) Cost: 5.928727\n",
            "Epoch   11/20 hypothesis: tensor([154.0536, 185.1120, 175.7599, 198.6098, 141.2181]) Cost: 5.926240\n",
            "Epoch   12/20 hypothesis: tensor([154.0535, 185.1118, 175.7610, 198.6093, 141.2182]) Cost: 5.923646\n",
            "Epoch   13/20 hypothesis: tensor([154.0533, 185.1115, 175.7620, 198.6086, 141.2183]) Cost: 5.921031\n",
            "Epoch   14/20 hypothesis: tensor([154.0532, 185.1112, 175.7631, 198.6081, 141.2183]) Cost: 5.918510\n",
            "Epoch   15/20 hypothesis: tensor([154.0530, 185.1109, 175.7641, 198.6075, 141.2184]) Cost: 5.915939\n",
            "Epoch   16/20 hypothesis: tensor([154.0529, 185.1106, 175.7652, 198.6069, 141.2184]) Cost: 5.913393\n",
            "Epoch   17/20 hypothesis: tensor([154.0527, 185.1103, 175.7662, 198.6063, 141.2185]) Cost: 5.910825\n",
            "Epoch   18/20 hypothesis: tensor([154.0526, 185.1100, 175.7673, 198.6057, 141.2185]) Cost: 5.908256\n",
            "Epoch   19/20 hypothesis: tensor([154.0524, 185.1097, 175.7683, 198.6051, 141.2186]) Cost: 5.905738\n",
            "Epoch   20/20 hypothesis: tensor([154.0523, 185.1094, 175.7694, 198.6045, 141.2187]) Cost: 5.903165\n"
          ]
        }
      ]
    }
  ]
}